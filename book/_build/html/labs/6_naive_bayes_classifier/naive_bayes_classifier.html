

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Week 13: Naive Bayes Classifiers &#8212; The Data Science Labs on Probability</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'labs/6_naive_bayes_classifier/naive_bayes_classifier';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction to Breadboards" href="../../extra_materials/intro_to_breadboards/intro_to_breadboards.html" />
    <link rel="prev" title="Week 11-12: Estimating Pi with a RNG" href="../4_rng/lab_08/lab_08_pi.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="The Data Science Labs on Probability - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="The Data Science Labs on Probability - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    About this Course
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction and Review</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_intro_and_review/lab_00/lab_00_intro.html">Week 1: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_intro_and_review/lab_01/lab_01_py_review.html">Week 2: Review of Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frequency</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_frequency/lab_02/lab_02_prob_freq.html">Week 3-4: Probability as a Frequency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_frequency/lab_03/lab_03_quantization.html">Week 5-6: Image Quantization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Video</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3_video/lab_04/lab_04_video_intro.html">Week 7: Acquiring and Manipulating Videos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3_video/lab_05/lab_05_motion.html">Week 8: Motion Detection</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">RNG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_rng/lab_06/lab_06_rng.html">Week 9: Random Number Generators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_rng/lab_07/lab_07_testing_rng.html">Week 10: Evaluating Random Number Generators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_rng/lab_08/lab_08_pi.html">Week 11-12: Estimating Pi with a RNG</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Week 13: Naive Bayes Classifiers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Extra Materials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../extra_materials/intro_to_breadboards/intro_to_breadboards.html">Introduction to Breadboards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../extra_materials/intro_to_latex/intro_to_latex.html">Introduction to <span class="math notranslate nohighlight">\(\LaTeX\)</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../extra_materials/pico_datasheet/pico_datasheet.html">Raspberry Pi Pico Pinout</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/TheDataScienceLabs/DSLab_Probability" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/TheDataScienceLabs/DSLab_Probability/issues/new?title=Issue%20on%20page%20%2Flabs/6_naive_bayes_classifier/naive_bayes_classifier.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/labs/6_naive_bayes_classifier/naive_bayes_classifier.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Week 13: Naive Bayes Classifiers</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-00-content-span"><span style="color:#d97f00;"> 00. Content </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-0-required-hardware-span"><span style="color:#d97f00;"> 0. Required Hardware </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-1-introduction-to-bayes-theorem-span"><span style="color:#d97f00;"> 1. Introduction to Bayes’ Theorem </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-formulation">Mathematical Formulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-1-the-disease-paradox-span"><span style="color:red"> Exercise 1: The Disease Paradox</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-2-changing-the-false-positive-rate-span"><span style="color:red"> Exercise 2: Changing the False Positive Rate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-2-naive-bayes-classification-span"><span style="color:#d97f00;"> 2. Naive Bayes Classification</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-classifiers">Introduction to Classifiers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features-and-labels">Features and Labels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-of-features-and-labels">Examples of Features and Labels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier">Naive Bayes Classifier</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How It Works</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes">1. <strong>Gaussian Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-naive-bayes">2. <strong>Multinomial Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bernoulli-naive-bayes">3. <strong>Bernoulli Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-naive-bayes">4. <strong>Categorical Naive Bayes</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-3-gaussian-naive-bayes-illustration-span"><span style="color:red"> Exercise 3: Gaussian Naive Bayes Illustration</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-3-a-simple-example-span"><span style="color:#d97f00;"> 3. A Simple Example </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-4-calculate-the-probabilities-span"><span style="color:red"> Exercise 4: Calculate the Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-5-calculate-the-conditional-probabilities-span"><span style="color:red"> Exercise 5: Calculate the Conditional Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-6-calculate-the-posterior-probabilities-span"><span style="color:red"> Exercise 6: Calculate the Posterior Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-7-the-multivariate-case-span"><span style="color:red"> Exercise 7: The Multivariate Case</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-4-heart-disease-span"><span style="color:#d97f00;"> 4. Heart disease </span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-8-building-intuition-span"><span style="color:red"> Exercise 8: Building Intuition</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-gaussian-naive-bayes-classifier">Training a Gaussian Naive Bayes Classifier</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-data-into-training-and-testing-sets">Splitting the Data into Training and Testing Sets</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-classifier">Training the Classifier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-the-classifier">Evaluating the Classifier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-accuracy">Calculating Accuracy</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-9-evaluating-the-model-span"><span style="color:red"> Exercise 9: Evaluating the model </span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-decision-boundaries">Visualizing Decision Boundaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-10-plotting-decision-boundaries-span"><span style="color:red"> Exercise 10: Plotting decision boundaries </span></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="week-13-naive-bayes-classifiers">
<h1>Week 13: Naive Bayes Classifiers<a class="headerlink" href="#week-13-naive-bayes-classifiers" title="Permalink to this heading">#</a></h1>
<p><font size="6"> Laboratory 9 </font> <br>
<font size="3"> Last updated November 11, 2024 </font></p>
<section id="span-style-color-d97f00-00-content-span">
<h2><span style="color:#d97f00;"> 00. Content </span><a class="headerlink" href="#span-style-color-d97f00-00-content-span" title="Permalink to this heading">#</a></h2>
<p><font size="5"> Mathematics </font></p>
<ul class="simple">
<li><p>Bayes’ Theorem</p></li>
</ul>
<p><font size="5"> Programming Skills </font></p>
<ul class="simple">
<li><p>Machine Learning</p></li>
</ul>
<p><font size="5"> Embedded Systems </font></p>
<ul class="simple">
<li><p>N/A</p></li>
</ul>
</section>
<section id="span-style-color-d97f00-0-required-hardware-span">
<h2><span style="color:#d97f00;"> 0. Required Hardware </span><a class="headerlink" href="#span-style-color-d97f00-0-required-hardware-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>N/A</p></li>
</ul>
<h3 style="color:green"> Write your name and email below: </h3>
<p><strong>Name:</strong></p>
<p><strong>Email:</strong></p>
</section>
<section id="span-style-color-d97f00-1-introduction-to-bayes-theorem-span">
<h2><span style="color:#d97f00;"> 1. Introduction to Bayes’ Theorem </span><a class="headerlink" href="#span-style-color-d97f00-1-introduction-to-bayes-theorem-span" title="Permalink to this heading">#</a></h2>
</section>
<section id="mathematical-formulation">
<h2>Mathematical Formulation<a class="headerlink" href="#mathematical-formulation" title="Permalink to this heading">#</a></h2>
<p>Bayes’ Theorem is a fundamental concept in probability theory that describes the relationship between conditional probabilities. Mathematically, it is expressed as:</p>
<div class="math notranslate nohighlight">
\[
P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A | B)\)</span> is the probability of event <span class="math notranslate nohighlight">\(A\)</span> occurring given that event <span class="math notranslate nohighlight">\(B\)</span> has occurred.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B | A)\)</span> is the probability of event <span class="math notranslate nohighlight">\(B\)</span> occurring given that event <span class="math notranslate nohighlight">\(A\)</span> has occurred.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span> and <span class="math notranslate nohighlight">\(P(B)\)</span> are the probabilities of events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> occurring independently.</p></li>
</ul>
<p>Bayes’ Theorem allows us to update our beliefs about the probability of an event based on new evidence. It provides a way to reverse conditional probabilities. In other words, if we know <span class="math notranslate nohighlight">\(P(B | A)\)</span>, we can find <span class="math notranslate nohighlight">\(P(A | B)\)</span> by considering the overall likelihoods of <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>.</p>
<p>Imagine you’re trying to determine how likely it is that someone has a disease (<span class="math notranslate nohighlight">\(A\)</span>) after they’ve received a positive test result (<span class="math notranslate nohighlight">\(B\)</span>). Bayes’ Theorem helps you combine the test accuracy with the prevalence of the disease to find the updated probability.</p>
<section id="span-style-color-red-exercise-1-the-disease-paradox-span">
<h3><span style="color:red"> Exercise 1: The Disease Paradox</span><a class="headerlink" href="#span-style-color-red-exercise-1-the-disease-paradox-span" title="Permalink to this heading">#</a></h3>
<p>Consider a rare disease that affects <strong>1 in 10,000</strong> people. A medical test has the following characteristics:</p>
<ul class="simple">
<li><p><strong>True Positive Rate</strong>: If a person has the disease, the test correctly identifies it <strong>99%</strong> of the time.</p></li>
<li><p><strong>False Positive Rate</strong>: If a person does not have the disease, the test incorrectly indicates they have it <strong>1%</strong> of the time.</p></li>
</ul>
<p>A randomly selected person from the general population takes the test and receives a <strong>positive</strong> result. Apply Bayes’ theorem to calculate the probability that this person actually has the disease.</p>
</section>
<section id="span-style-color-red-exercise-2-changing-the-false-positive-rate-span">
<h3><span style="color:red"> Exercise 2: Changing the False Positive Rate</span><a class="headerlink" href="#span-style-color-red-exercise-2-changing-the-false-positive-rate-span" title="Permalink to this heading">#</a></h3>
<p>For what value of the false positive rate would the probability of having the disease given a positive test result be equal to 50%? In other words, find the value of <span class="math notranslate nohighlight">\(P(T | \overline{D})\)</span> that makes <span class="math notranslate nohighlight">\(P(D | T) = 0.5\)</span>. <strong>Give your answer as a LaTeX equation, not a python script</strong></p>
</section>
</section>
<section id="span-style-color-d97f00-2-naive-bayes-classification-span">
<h2><span style="color:#d97f00;"> 2. Naive Bayes Classification</span><a class="headerlink" href="#span-style-color-d97f00-2-naive-bayes-classification-span" title="Permalink to this heading">#</a></h2>
</section>
<section id="introduction-to-classifiers">
<h2>Introduction to Classifiers<a class="headerlink" href="#introduction-to-classifiers" title="Permalink to this heading">#</a></h2>
<p>In machine learning, a <strong>classifier</strong> is an algorithm that assigns a category or class label to input data based on its features. Classifiers are essential tools for tasks like detecting spam emails, image recognition, and medical diagnosis.</p>
<section id="features-and-labels">
<h3>Features and Labels<a class="headerlink" href="#features-and-labels" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Features</strong>: The measurable properties or characteristics of the data used for analysis. They are the inputs to the classifier.</p></li>
<li><p><strong>Class Labels</strong>: The output categories or classes that we aim to predict. They represent the classification outcome.</p></li>
</ul>
</section>
<section id="examples-of-features-and-labels">
<h3>Examples of Features and Labels<a class="headerlink" href="#examples-of-features-and-labels" title="Permalink to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Classifier Type</strong></p></th>
<th class="head"><p><strong>Features</strong></p></th>
<th class="head"><p><strong>Class Labels</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Spam Email Classifier</strong></p></td>
<td><p>Words in the email, email length, presence of links, sender’s address</p></td>
<td><p>“Spam” and “Not Spam”</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Medical Diagnosis Classifier</strong></p></td>
<td><p>Patient age, blood pressure, cholesterol level, presence of specific symptoms</p></td>
<td><p>“Disease” and “No Disease” (or specific diseases like “Diabetes,” “Hypertension”)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Image Classifier</strong></p></td>
<td><p>Pixel values, color histograms, shapes, textures</p></td>
<td><p>“Dog,” “Cat,” “Bird,” etc.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="naive-bayes-classifier">
<h2>Naive Bayes Classifier<a class="headerlink" href="#naive-bayes-classifier" title="Permalink to this heading">#</a></h2>
<p>The <strong>Naive Bayes classifier</strong> is a simple yet powerful probabilistic classifier based on Bayes’ Theorem. It assumes that the features are independent given the class label—a “naive” assumption that simplifies computation but still often yields effective results.</p>
<section id="how-it-works">
<h3>How It Works<a class="headerlink" href="#how-it-works" title="Permalink to this heading">#</a></h3>
<p>Given a feature vector <span class="math notranslate nohighlight">\(X = (x_1, x_2, ..., x_n)\)</span> and a class <span class="math notranslate nohighlight">\(C\)</span>, the Naive Bayes classifier computes the posterior probability <span class="math notranslate nohighlight">\(P(C | X)\)</span> and assigns <span class="math notranslate nohighlight">\(X\)</span> to the class with the highest posterior probability.</p>
<p>The classifier uses Bayes’ Theorem:</p>
<div class="math notranslate nohighlight">
\[
P(C | X) = \frac{P(X | C) \cdot P(C)}{P(X)}
\]</div>
<p>There are several different types of Naive Bayes classifiers. Each assumes a different distribution for the features.</p>
<section id="gaussian-naive-bayes">
<h4>1. <strong>Gaussian Naive Bayes</strong><a class="headerlink" href="#gaussian-naive-bayes" title="Permalink to this heading">#</a></h4>
<p>This is used when the probabilities of the features are continuous and are assumed to follow a Gaussian (normal) distribution. For a feature <span class="math notranslate nohighlight">\(x_i\)</span> given class <span class="math notranslate nohighlight">\(C\)</span>, the likelihood is modeled as:
$<span class="math notranslate nohighlight">\(
P(x_i \mid C) = \frac{1}{\sqrt{2\pi\sigma_C^2}} \exp\left(-\frac{(x_i - \mu_C)^2}{2\sigma_C^2}\right)
\)</span><span class="math notranslate nohighlight">\(
where \)</span> \mu_C <span class="math notranslate nohighlight">\( is the mean and \)</span> \sigma_C^2 <span class="math notranslate nohighlight">\( is the variance of the feature in class \)</span>C$.</p>
</section>
<section id="multinomial-naive-bayes">
<h4>2. <strong>Multinomial Naive Bayes</strong><a class="headerlink" href="#multinomial-naive-bayes" title="Permalink to this heading">#</a></h4>
<p>This is suited for discrete data, especially when features represent counts (like word frequencies in text classification). It assumes that the features follow a multinomial distribution. For a feature vector <span class="math notranslate nohighlight">\( \mathbf{x} = (x_1, x_2, ..., x_n) \)</span>, the likelihood is given by:
$<span class="math notranslate nohighlight">\(
P(\mathbf{x} \mid C) = P(C) \prod_{i=1}^{n} P(x_i \mid C)^{x_i}
\)</span><span class="math notranslate nohighlight">\(
Here, \)</span> P(x_i \mid C) <span class="math notranslate nohighlight">\( is the probability of feature \)</span>x_i<span class="math notranslate nohighlight">\( given class \)</span>C<span class="math notranslate nohighlight">\(, and \)</span> x_i <span class="math notranslate nohighlight">\( represents the count of feature \)</span>i$.</p>
</section>
<section id="bernoulli-naive-bayes">
<h4>3. <strong>Bernoulli Naive Bayes</strong><a class="headerlink" href="#bernoulli-naive-bayes" title="Permalink to this heading">#</a></h4>
<p>This is designed for binary feature vectors, where each feature can either be 0 or 1 (presence or absence). The likelihood for Bernoulli Naive Bayes is:
$<span class="math notranslate nohighlight">\(
P(\mathbf{x} \mid C) = P(C) \prod_{i=1}^{n} P(x_i \mid C)^{x_i} (1 - P(x_i \mid C))^{(1 - x_i)}
\)</span><span class="math notranslate nohighlight">\(
where \)</span>x_i<span class="math notranslate nohighlight">\( is 1 if the feature is present and 0 otherwise, and \)</span>P(x_i \mid C)<span class="math notranslate nohighlight">\( is the probability of feature \)</span>x_i<span class="math notranslate nohighlight">\( being 1 given the class \)</span>C$.</p>
</section>
<section id="categorical-naive-bayes">
<h4>4. <strong>Categorical Naive Bayes</strong><a class="headerlink" href="#categorical-naive-bayes" title="Permalink to this heading">#</a></h4>
<p>This variant is used when the features are categorical (not ordered). Each feature can take on a finite number of discrete values, and it is modeled using a categorical distribution. For a feature <span class="math notranslate nohighlight">\(x_i\)</span> that can take on one of <span class="math notranslate nohighlight">\(k\)</span> values:
$<span class="math notranslate nohighlight">\(
P(x_i = v_k \mid C) = P(v_k \mid C)
\)</span><span class="math notranslate nohighlight">\(
where \)</span>P(v_k \mid C)<span class="math notranslate nohighlight">\( is the probability that feature \)</span>x_i<span class="math notranslate nohighlight">\( takes the value \)</span>v_k<span class="math notranslate nohighlight">\( given class \)</span>C$.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Naive Bayes Variant</strong></p></th>
<th class="head"><p><strong>Best Use Case</strong></p></th>
<th class="head"><p><strong>Feature Types</strong></p></th>
<th class="head"><p><strong>Example Features</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Gaussian Naive Bayes</strong></p></td>
<td><p>Features are continuous and assume a normal (Gaussian) distribution</p></td>
<td><p>Continuous</p></td>
<td><p>Exam scores in a calculus class, height of a population</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Multinomial Naive Bayes</strong></p></td>
<td><p>Features represent counts or frequency of occurrences</p></td>
<td><p>Count data, frequency data</p></td>
<td><p>Frequencies of words in text classification</p></td>
</tr>
<tr class="row-even"><td><p><strong>Bernoulli Naive Bayes</strong></p></td>
<td><p>Features are binary indicators (e.g., presence/absence of a feature)</p></td>
<td><p>Binary</p></td>
<td><p>Presence of a disease in medical diagnosis</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Categorical Naive Bayes</strong></p></td>
<td><p>Features are categorical and do not assume any ordering or continuity</p></td>
<td><p>Categorical/discrete</p></td>
<td><p>Weather (e.g., sunny, cloudy, rainy)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="span-style-color-red-exercise-3-gaussian-naive-bayes-illustration-span">
<h3><span style="color:red"> Exercise 3: Gaussian Naive Bayes Illustration</span><a class="headerlink" href="#span-style-color-red-exercise-3-gaussian-naive-bayes-illustration-span" title="Permalink to this heading">#</a></h3>
<p>The following code generates and plots two classes of data points with Gaussian distributions.</p>
<ol class="arabic simple">
<li><p>Fit the classes to Gaussian distributions and plot the data with the Gaussian curves.</p></li>
<li><p>Find the value of <span class="math notranslate nohighlight">\(x\)</span> so that the probability of a data point belonging to each of the two classes is equal. Plot a vertical line at this value. This point is the <strong>decision boundary</strong> between the two classes.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Set random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Parameters for Class 0</span>
<span class="n">mean0</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">std0</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Standard deviation</span>

<span class="c1"># Parameters for Class 1</span>
<span class="n">mean1</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">std1</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Standard deviation</span>

<span class="c1"># Number of samples per class</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Generate data for Class 0</span>
<span class="n">X0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean0</span><span class="p">,</span> <span class="n">std0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="n">y0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="c1"># Generate data for Class 1</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">std1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="c1"># Combine the data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y0</span><span class="p">,</span> <span class="n">y1</span><span class="p">))</span>


<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X0</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;tab:red&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Feature Value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of Synthetic 1D Dataset&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/783fd9f4d6e6c2034658ae3684fdc1489b9dcd152dcff15b4527b2100bcc4235.png" src="../../_images/783fd9f4d6e6c2034658ae3684fdc1489b9dcd152dcff15b4527b2100bcc4235.png" />
</div>
</div>
</section>
</section>
<section id="span-style-color-d97f00-3-a-simple-example-span">
<h2><span style="color:#d97f00;"> 3. A Simple Example </span><a class="headerlink" href="#span-style-color-d97f00-3-a-simple-example-span" title="Permalink to this heading">#</a></h2>
<p>In this example, we’ll demonstrate <strong>Categorical Naive Bayes</strong> classification using only one categorical feature: <strong>Weather</strong>.</p>
</section>
<section id="problem-statement">
<h2>Problem Statement<a class="headerlink" href="#problem-statement" title="Permalink to this heading">#</a></h2>
<p>Suppose we have data about whether children decide to <strong>Play</strong> outside based on the <strong>Weather</strong> conditions. The possible weather conditions are:</p>
<ul class="simple">
<li><p><strong>Sunny</strong></p></li>
<li><p><strong>Overcast</strong></p></li>
<li><p><strong>Rainy</strong></p></li>
</ul>
<p>Our dataset:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Day</p></th>
<th class="head"><p>Weather</p></th>
<th class="head"><p>Play</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Sunny</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Sunny</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Overcast</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Rainy</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>Rainy</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>Rainy</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>Overcast</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>Sunny</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>Sunny</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>Rainy</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><p>Sunny</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><p>Overcast</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><p>Overcast</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><p>Rainy</p></td>
<td><p>No</p></td>
</tr>
</tbody>
</table>
</div>
<p>Predict whether children will <strong>Play</strong> or <strong>Not Play</strong> on a <strong>Sunny</strong> day.</p>
<section id="span-style-color-red-exercise-4-calculate-the-probabilities-span">
<h3><span style="color:red"> Exercise 4: Calculate the Probabilities</span><a class="headerlink" href="#span-style-color-red-exercise-4-calculate-the-probabilities-span" title="Permalink to this heading">#</a></h3>
<p>Calculate the prior probabilities of each class (Play = Yes or No):</p>
</section>
<section id="span-style-color-red-exercise-5-calculate-the-conditional-probabilities-span">
<h3><span style="color:red"> Exercise 5: Calculate the Conditional Probabilities</span><a class="headerlink" href="#span-style-color-red-exercise-5-calculate-the-conditional-probabilities-span" title="Permalink to this heading">#</a></h3>
<p>Calculate the likelihood of each weather condition given the class (e.g. <span class="math notranslate nohighlight">\( P(\text{Weather | Play = Yes})\)</span>).</p>
</section>
<section id="span-style-color-red-exercise-6-calculate-the-posterior-probabilities-span">
<h3><span style="color:red"> Exercise 6: Calculate the Posterior Probabilities</span><a class="headerlink" href="#span-style-color-red-exercise-6-calculate-the-posterior-probabilities-span" title="Permalink to this heading">#</a></h3>
<p>Predict whether children will <strong>Play</strong> or <strong>Not Play</strong> on a <strong>Sunny</strong> day.</p>
</section>
<section id="span-style-color-red-exercise-7-the-multivariate-case-span">
<h3><span style="color:red"> Exercise 7: The Multivariate Case</span><a class="headerlink" href="#span-style-color-red-exercise-7-the-multivariate-case-span" title="Permalink to this heading">#</a></h3>
<p>Write an expression for the posterior probability <span class="math notranslate nohighlight">\( P(C | X) \)</span> in the multivariate case, where <span class="math notranslate nohighlight">\( X = (x_1, x_2, ..., x_n) \)</span> represents multiple features. Express your answer in terms of <span class="math notranslate nohighlight">\(x_i\)</span>, assuming that the features are independent given the class label <span class="math notranslate nohighlight">\(C\)</span>.</p>
</section>
</section>
<section id="span-style-color-d97f00-4-heart-disease-span">
<h2><span style="color:#d97f00;"> 4. Heart disease </span><a class="headerlink" href="#span-style-color-d97f00-4-heart-disease-span" title="Permalink to this heading">#</a></h2>
<p>The UCI Machine Learning Repository’s Heart Disease dataset is a popular benchmark for classification tasks in machine learning. It contains medical data from individuals, with the goal of predicting the presence or absence of heart disease based on several attributes like age, sex, cholesterol levels, blood pressure, and others. This dataset is ideal for demonstrating classification algorithms like Naive Bayes because it includes both continuous and categorical features. To use this dataset in Python, you can install the <code class="docutils literal notranslate"><span class="pre">ucimlrepo</span></code> package, which provides easy access to datasets from the UCI repository. Install the package using the command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>ucimlrepo
</pre></div>
</div>
<p>After installation, you can load the heart disease dataset as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ucimlrepo</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_ucirepo</span> 
<span class="n">heart_disease</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span> 
  
<span class="c1"># data (as pandas dataframes) </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">heart_disease</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span> 
<span class="n">y</span> <span class="o">=</span> <span class="n">heart_disease</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span> 
</pre></div>
</div>
</div>
</div>
<p>You can examine the metadata and variables to learn more about the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># metadata </span>
<span class="nb">print</span><span class="p">(</span><span class="n">heart_disease</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span> 
  
<span class="c1"># variable information </span>
<span class="nb">print</span><span class="p">(</span><span class="n">heart_disease</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;uci_id&#39;: 45, &#39;name&#39;: &#39;Heart Disease&#39;, &#39;repository_url&#39;: &#39;https://archive.ics.uci.edu/dataset/45/heart+disease&#39;, &#39;data_url&#39;: &#39;https://archive.ics.uci.edu/static/public/45/data.csv&#39;, &#39;abstract&#39;: &#39;4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach&#39;, &#39;area&#39;: &#39;Health and Medicine&#39;, &#39;tasks&#39;: [&#39;Classification&#39;], &#39;characteristics&#39;: [&#39;Multivariate&#39;], &#39;num_instances&#39;: 303, &#39;num_features&#39;: 13, &#39;feature_types&#39;: [&#39;Categorical&#39;, &#39;Integer&#39;, &#39;Real&#39;], &#39;demographics&#39;: [&#39;Age&#39;, &#39;Sex&#39;], &#39;target_col&#39;: [&#39;num&#39;], &#39;index_col&#39;: None, &#39;has_missing_values&#39;: &#39;yes&#39;, &#39;missing_values_symbol&#39;: &#39;NaN&#39;, &#39;year_of_dataset_creation&#39;: 1989, &#39;last_updated&#39;: &#39;Fri Nov 03 2023&#39;, &#39;dataset_doi&#39;: &#39;10.24432/C52P4X&#39;, &#39;creators&#39;: [&#39;Andras Janosi&#39;, &#39;William Steinbrunn&#39;, &#39;Matthias Pfisterer&#39;, &#39;Robert Detrano&#39;], &#39;intro_paper&#39;: {&#39;ID&#39;: 231, &#39;type&#39;: &#39;NATIVE&#39;, &#39;title&#39;: &#39;International application of a new probability algorithm for the diagnosis of coronary artery disease.&#39;, &#39;authors&#39;: &#39;R. Detrano, A. Jánosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, V. Froelicher&#39;, &#39;venue&#39;: &#39;American Journal of Cardiology&#39;, &#39;year&#39;: 1989, &#39;journal&#39;: None, &#39;DOI&#39;: None, &#39;URL&#39;: &#39;https://www.semanticscholar.org/paper/a7d714f8f87bfc41351eb5ae1e5472f0ebbe0574&#39;, &#39;sha&#39;: None, &#39;corpus&#39;: None, &#39;arxiv&#39;: None, &#39;mag&#39;: None, &#39;acl&#39;: None, &#39;pmid&#39;: &#39;2756873&#39;, &#39;pmcid&#39;: None}, &#39;additional_info&#39;: {&#39;summary&#39;: &#39;This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The &quot;goal&quot; field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \n   \nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\n\nOne file has been &quot;processed&quot;, that one containing the Cleveland database.  All four unprocessed files also exist in this directory.\n\nTo see Test Costs (donated by Peter Turney), please see the folder &quot;Costs&quot; &#39;, &#39;purpose&#39;: None, &#39;funded_by&#39;: None, &#39;instances_represent&#39;: None, &#39;recommended_data_splits&#39;: None, &#39;sensitive_data&#39;: None, &#39;preprocessing_description&#39;: None, &#39;variable_info&#39;: &#39;Only 14 attributes used:\r\n      1. #3  (age)       \r\n      2. #4  (sex)       \r\n      3. #9  (cp)        \r\n      4. #10 (trestbps)  \r\n      5. #12 (chol)      \r\n      6. #16 (fbs)       \r\n      7. #19 (restecg)   \r\n      8. #32 (thalach)   \r\n      9. #38 (exang)     \r\n      10. #40 (oldpeak)   \r\n      11. #41 (slope)     \r\n      12. #44 (ca)        \r\n      13. #51 (thal)      \r\n      14. #58 (num)       (the predicted attribute)\r\n\r\nComplete attribute documentation:\r\n      1 id: patient identification number\r\n      2 ccf: social security number (I replaced this with a dummy value of 0)\r\n      3 age: age in years\r\n      4 sex: sex (1 = male; 0 = female)\r\n      5 painloc: chest pain location (1 = substernal; 0 = otherwise)\r\n      6 painexer (1 = provoked by exertion; 0 = otherwise)\r\n      7 relrest (1 = relieved after rest; 0 = otherwise)\r\n      8 pncaden (sum of 5, 6, and 7)\r\n      9 cp: chest pain type\r\n        -- Value 1: typical angina\r\n        -- Value 2: atypical angina\r\n        -- Value 3: non-anginal pain\r\n        -- Value 4: asymptomatic\r\n     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\r\n     11 htn\r\n     12 chol: serum cholestoral in mg/dl\r\n     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\r\n     14 cigs (cigarettes per day)\r\n     15 years (number of years as a smoker)\r\n     16 fbs: (fasting blood sugar &gt; 120 mg/dl)  (1 = true; 0 = false)\r\n     17 dm (1 = history of diabetes; 0 = no such history)\r\n     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\r\n     19 restecg: resting electrocardiographic results\r\n        -- Value 0: normal\r\n        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV)\r\n        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes\&#39; criteria\r\n     20 ekgmo (month of exercise ECG reading)\r\n     21 ekgday(day of exercise ECG reading)\r\n     22 ekgyr (year of exercise ECG reading)\r\n     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\r\n     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\r\n     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\r\n     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\r\n     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\r\n     28 proto: exercise protocol\r\n          1 = Bruce     \r\n          2 = Kottus\r\n          3 = McHenry\r\n          4 = fast Balke\r\n          5 = Balke\r\n          6 = Noughton \r\n          7 = bike 150 kpa min/min  (Not sure if &quot;kpa min/min&quot; is what was written!)\r\n          8 = bike 125 kpa min/min  \r\n          9 = bike 100 kpa min/min\r\n         10 = bike 75 kpa min/min\r\n         11 = bike 50 kpa min/min\r\n         12 = arm ergometer\r\n     29 thaldur: duration of exercise test in minutes\r\n     30 thaltime: time when ST measure depression was noted\r\n     31 met: mets achieved\r\n     32 thalach: maximum heart rate achieved\r\n     33 thalrest: resting heart rate\r\n     34 tpeakbps: peak exercise blood pressure (first of 2 parts)\r\n     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\r\n     36 dummy\r\n     37 trestbpd: resting blood pressure\r\n     38 exang: exercise induced angina (1 = yes; 0 = no)\r\n     39 xhypo: (1 = yes; 0 = no)\r\n     40 oldpeak = ST depression induced by exercise relative to rest\r\n     41 slope: the slope of the peak exercise ST segment\r\n        -- Value 1: upsloping\r\n        -- Value 2: flat\r\n        -- Value 3: downsloping\r\n     42 rldv5: height at rest\r\n     43 rldv5e: height at peak exercise\r\n     44 ca: number of major vessels (0-3) colored by flourosopy\r\n     45 restckm: irrelevant\r\n     46 exerckm: irrelevant\r\n     47 restef: rest raidonuclid (sp?) ejection fraction\r\n     48 restwm: rest wall (sp?) motion abnormality\r\n        0 = none\r\n        1 = mild or moderate\r\n        2 = moderate or severe\r\n        3 = akinesis or dyskmem (sp?)\r\n     49 exeref: exercise radinalid (sp?) ejection fraction\r\n     50 exerwm: exercise wall (sp?) motion \r\n     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\r\n     52 thalsev: not used\r\n     53 thalpul: not used\r\n     54 earlobe: not used\r\n     55 cmo: month of cardiac cath (sp?)  (perhaps &quot;call&quot;)\r\n     56 cday: day of cardiac cath (sp?)\r\n     57 cyr: year of cardiac cath (sp?)\r\n     58 num: diagnosis of heart disease (angiographic disease status)\r\n        -- Value 0: &lt; 50% diameter narrowing\r\n        -- Value 1: &gt; 50% diameter narrowing\r\n        (in any major vessel: attributes 59 through 68 are vessels)\r\n     59 lmt\r\n     60 ladprox\r\n     61 laddist\r\n     62 diag\r\n     63 cxmain\r\n     64 ramus\r\n     65 om1\r\n     66 om2\r\n     67 rcaprox\r\n     68 rcadist\r\n     69 lvx1: not used\r\n     70 lvx2: not used\r\n     71 lvx3: not used\r\n     72 lvx4: not used\r\n     73 lvf: not used\r\n     74 cathef: not used\r\n     75 junk: not used\r\n     76 name: last name of patient  (I replaced this with the dummy string &quot;name&quot;)&#39;, &#39;citation&#39;: None}}
        name     role         type demographic  \
0        age  Feature      Integer         Age   
1        sex  Feature  Categorical         Sex   
2         cp  Feature  Categorical        None   
3   trestbps  Feature      Integer        None   
4       chol  Feature      Integer        None   
5        fbs  Feature  Categorical        None   
6    restecg  Feature  Categorical        None   
7    thalach  Feature      Integer        None   
8      exang  Feature  Categorical        None   
9    oldpeak  Feature      Integer        None   
10     slope  Feature  Categorical        None   
11        ca  Feature      Integer        None   
12      thal  Feature  Categorical        None   
13       num   Target      Integer        None   

                                          description  units missing_values  
0                                                None  years             no  
1                                                None   None             no  
2                                                None   None             no  
3   resting blood pressure (on admission to the ho...  mm Hg             no  
4                                   serum cholestoral  mg/dl             no  
5                     fasting blood sugar &gt; 120 mg/dl   None             no  
6                                                None   None             no  
7                         maximum heart rate achieved   None             no  
8                             exercise induced angina   None             no  
9   ST depression induced by exercise relative to ...   None             no  
10                                               None   None             no  
11  number of major vessels (0-3) colored by flour...   None            yes  
12                                               None   None            yes  
13                         diagnosis of heart disease   None             no  
</pre></div>
</div>
</div>
</div>
<p>We will simplify the problem by converting the target variable from its original range of 0 to 4 into a binary classification: 0 for no heart disease and 1 for the presence of heart disease.</p>
<p>Because we will be fitting the data to a gaussian model, we will discard binary features, such as exercise-induced angina (exang), and multinomial features, such as chest pain type (cp).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">applymap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;trestbps&#39;</span><span class="p">,</span> <span class="s1">&#39;chol&#39;</span><span class="p">,</span> <span class="s1">&#39;thalach&#39;</span><span class="p">,</span> <span class="s1">&#39;oldpeak&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\chris\AppData\Local\Temp\ipykernel_16756\3801226080.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  y = y.applymap(lambda x: 0 if x == 0 else 1)
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-red-exercise-8-building-intuition-span">
<h3><span style="color:red"> Exercise 8: Building Intuition</span><a class="headerlink" href="#span-style-color-red-exercise-8-building-intuition-span" title="Permalink to this heading">#</a></h3>
<p>Choose two features, and make a contour plot of the likelihood of heart disease as a function of these features in matplotlib.</p>
<p><em>Hint: The easiest way to do this is probably to make a scatter plot where the colors of the points correspond to the likelihood of having heart disease`.</em></p>
</section>
<section id="training-a-gaussian-naive-bayes-classifier">
<h3>Training a Gaussian Naive Bayes Classifier<a class="headerlink" href="#training-a-gaussian-naive-bayes-classifier" title="Permalink to this heading">#</a></h3>
<p>In this section, we will train a Gaussian Naive Bayes classifier using scikit-learn to predict the presence and severity of heart disease based on patient data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Assuming age, trestbps, chol, thalach, oldpeak, ca, and y are already defined numpy arrays</span>

<span class="c1"># Stack the feature arrays into a single feature matrix</span>
<span class="c1"># X = np.column_stack((age, trestbps, chol, thalach, oldpeak, ca))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="c1"># Check the shape of X and y</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of X:&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of y:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of X: (303, 5)
Shape of y: (303, 1)
</pre></div>
</div>
</div>
</div>
<p>Here, we have combined all the feature arrays into a two-dimensional feature matrix <code class="docutils literal notranslate"><span class="pre">X</span></code>, where each row represents a patient, and each column represents a feature.</p>
<section id="splitting-the-data-into-training-and-testing-sets">
<h4>Splitting the Data into Training and Testing Sets<a class="headerlink" href="#splitting-the-data-into-training-and-testing-sets" title="Permalink to this heading">#</a></h4>
<p>We will split the data into training and testing sets to evaluate the performance of our classifier on unseen data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the data: 80% training and 20% testing</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Check the shapes of the splits</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set shape:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing set shape:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set shape: (242, 5)
Testing set shape: (61, 5)
</pre></div>
</div>
</div>
</div>
<p>We use <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> from scikit-learn to randomly split the dataset while preserving the distribution of the target variable.</p>
</section>
<section id="training-the-classifier">
<h4>Training the Classifier<a class="headerlink" href="#training-the-classifier" title="Permalink to this heading">#</a></h4>
<p>Now, we will instantiate the Gaussian Naive Bayes classifier and train it on the training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Train the classifier</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\chris\miniconda3\envs\qutip-env\Lib\site-packages\sklearn\utils\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GaussianNB<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html">?<span>Documentation for GaussianNB</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GaussianNB()</pre></div> </div></div></div></div></div></div>
</div>
</section>
<section id="evaluating-the-classifier">
<h4>Evaluating the Classifier<a class="headerlink" href="#evaluating-the-classifier" title="Permalink to this heading">#</a></h4>
<p>We will evaluate the classifier’s performance using a confusion matrix, which provides a summary of prediction results.</p>
<p>The confusion matrix provides the following information:</p>
<ul class="simple">
<li><p><strong>True Positives (TP)</strong>: Correctly predicted positive observations.</p></li>
<li><p><strong>True Negatives (TN)</strong>: Correctly predicted negative observations.</p></li>
<li><p><strong>False Positives (FP)</strong>: Incorrectly predicted positive observations.</p></li>
<li><p><strong>False Negatives (FN)</strong>: Incorrectly predicted negative observations.</p></li>
</ul>
<p>By analyzing the confusion matrix, we can understand where the classifier is making mistakes and how it can be improved.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Make predictions on the test set</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Display the confusion matrix</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/071ffed5aa7325eb457f80938134ff3456ec4bca858ae6c7e1937b64e6d8fe50.png" src="../../_images/071ffed5aa7325eb457f80938134ff3456ec4bca858ae6c7e1937b64e6d8fe50.png" />
</div>
</div>
</section>
<section id="calculating-accuracy">
<h4>Calculating Accuracy<a class="headerlink" href="#calculating-accuracy" title="Permalink to this heading">#</a></h4>
<p>We can also evaluate the model’s <strong>accuracy</strong>. Accuracy measures how often the classifier’s predictions are correct, and it’s calculated using the following formula:</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}
\]</div>
<p>In this case:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">y_test</span></code></strong> contains the true labels for the test dataset. These are the correct answers, the ground truth.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">y_pred</span></code></strong> contains the predicted labels, which are the guesses made by the classifier for the test data.</p></li>
</ul>
<p>The function <code class="docutils literal notranslate"><span class="pre">accuracy_score(y_test,</span> <span class="pre">y_pred)</span></code> compares the predicted labels (<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>) with the actual labels (<code class="docutils literal notranslate"><span class="pre">y_test</span></code>) to count how many predictions are correct. It then divides the number of correct predictions by the total number of predictions to calculate the accuracy.</p>
<p>For example, if we had 100 test samples and the classifier predicted 90 of them correctly, the accuracy would be:</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{90}{100} = 0.90
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy of the classifier:&quot;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy of the classifier: 0.7377049180327869
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="span-style-color-red-exercise-9-evaluating-the-model-span">
<h3><span style="color:red"> Exercise 9: Evaluating the model </span><a class="headerlink" href="#span-style-color-red-exercise-9-evaluating-the-model-span" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>From the confusion matrix, are the true positives, true negatives, false positives, and false negatives for this model?</p></li>
<li><p>Which is a more meaningful way to evaluate the model’s performance: accuracy or the confusion matrix? Why?</p></li>
<li><p>Is the classifier a good model? Why or why not?</p></li>
</ul>
</section>
</section>
<section id="visualizing-decision-boundaries">
<h2>Visualizing Decision Boundaries<a class="headerlink" href="#visualizing-decision-boundaries" title="Permalink to this heading">#</a></h2>
<p>To visualize the decision boundaries, we can plot the classifier’s predictions over a grid of feature values. Since we cannot plot in more than two dimensions, we’ll select pairs of features.</p>
<p>The following code takes two features from the matrix of features and trains a model using those features alone. It then plots the decision boundaries for the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.colors</span><span class="w"> </span><span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Feature names for labeling</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;trestbps&#39;</span><span class="p">]</span>

<span class="c1"># Define colormap for 5 classes</span>
<span class="n">cmap_light</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">([</span><span class="s1">&#39;#FFAAAA&#39;</span><span class="p">,</span> <span class="s1">&#39;#AAFFAA&#39;</span><span class="p">,</span> <span class="s1">&#39;#AAAAFF&#39;</span><span class="p">,</span> <span class="s1">&#39;#FFAAFF&#39;</span><span class="p">,</span> <span class="s1">&#39;#AAFFFF&#39;</span><span class="p">]))</span>
<span class="n">cmap_bold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">([</span><span class="s1">&#39;tab:red&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:green&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:blue&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:purple&#39;</span><span class="p">,</span> <span class="s1">&#39;tab:cyan&#39;</span><span class="p">])</span>

<span class="c1"># Select two features to plot</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>

<span class="n">X_pair</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span>
<span class="n">y_pair</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="c1"># Create meshgrid</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>

<span class="c1"># Fit classifier on the pair of features</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_pair</span><span class="p">,</span> <span class="n">y_pair</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Plotting decision boundary</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_light</span><span class="p">)</span>

<span class="c1"># Plotting the actual data points</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_pair</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_pair</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">ListedColormap</span><span class="p">(</span><span class="n">cmap_bold</span><span class="p">),</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_names</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision Boundary using features &#39;</span><span class="si">{</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39; and &#39;</span><span class="si">{</span><span class="n">feature_names</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

<span class="c1"># Custom legend handling</span>
<span class="n">legend1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">*</span><span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">legend1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>c:\Users\chris\miniconda3\envs\qutip-env\Lib\site-packages\sklearn\utils\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1678d3fa790&gt;
</pre></div>
</div>
<img alt="../../_images/c08fd65ce29a37eef934875b6f57fe58e9d5d8a41ccc67d47496f31a31e967b1.png" src="../../_images/c08fd65ce29a37eef934875b6f57fe58e9d5d8a41ccc67d47496f31a31e967b1.png" />
</div>
</div>
<section id="span-style-color-red-exercise-10-plotting-decision-boundaries-span">
<h3><span style="color:red"> Exercise 10: Plotting decision boundaries </span><a class="headerlink" href="#span-style-color-red-exercise-10-plotting-decision-boundaries-span" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Plot the decision boundaries for different pairs of features.</p></li>
<li><p>Which pairs of features seem to be the best predictors of heart disease? Which pairs of features seem to be poor predictors of heart disease?</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./labs/6_naive_bayes_classifier"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../4_rng/lab_08/lab_08_pi.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Week 11-12: Estimating Pi with a RNG</p>
      </div>
    </a>
    <a class="right-next"
       href="../../extra_materials/intro_to_breadboards/intro_to_breadboards.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Breadboards</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-00-content-span"><span style="color:#d97f00;"> 00. Content </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-0-required-hardware-span"><span style="color:#d97f00;"> 0. Required Hardware </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-1-introduction-to-bayes-theorem-span"><span style="color:#d97f00;"> 1. Introduction to Bayes’ Theorem </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-formulation">Mathematical Formulation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-1-the-disease-paradox-span"><span style="color:red"> Exercise 1: The Disease Paradox</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-2-changing-the-false-positive-rate-span"><span style="color:red"> Exercise 2: Changing the False Positive Rate</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-2-naive-bayes-classification-span"><span style="color:#d97f00;"> 2. Naive Bayes Classification</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-classifiers">Introduction to Classifiers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#features-and-labels">Features and Labels</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-of-features-and-labels">Examples of Features and Labels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#naive-bayes-classifier">Naive Bayes Classifier</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-works">How It Works</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes">1. <strong>Gaussian Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multinomial-naive-bayes">2. <strong>Multinomial Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bernoulli-naive-bayes">3. <strong>Bernoulli Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-naive-bayes">4. <strong>Categorical Naive Bayes</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-3-gaussian-naive-bayes-illustration-span"><span style="color:red"> Exercise 3: Gaussian Naive Bayes Illustration</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-3-a-simple-example-span"><span style="color:#d97f00;"> 3. A Simple Example </span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement">Problem Statement</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-4-calculate-the-probabilities-span"><span style="color:red"> Exercise 4: Calculate the Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-5-calculate-the-conditional-probabilities-span"><span style="color:red"> Exercise 5: Calculate the Conditional Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-6-calculate-the-posterior-probabilities-span"><span style="color:red"> Exercise 6: Calculate the Posterior Probabilities</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-7-the-multivariate-case-span"><span style="color:red"> Exercise 7: The Multivariate Case</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-d97f00-4-heart-disease-span"><span style="color:#d97f00;"> 4. Heart disease </span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-8-building-intuition-span"><span style="color:red"> Exercise 8: Building Intuition</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-gaussian-naive-bayes-classifier">Training a Gaussian Naive Bayes Classifier</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-the-data-into-training-and-testing-sets">Splitting the Data into Training and Testing Sets</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-classifier">Training the Classifier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-the-classifier">Evaluating the Classifier</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-accuracy">Calculating Accuracy</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-9-evaluating-the-model-span"><span style="color:red"> Exercise 9: Evaluating the model </span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-decision-boundaries">Visualizing Decision Boundaries</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-red-exercise-10-plotting-decision-boundaries-span"><span style="color:red"> Exercise 10: Plotting decision boundaries </span></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mireille Boutin, Alden Bradford
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>This work is licensed under a 
<a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>