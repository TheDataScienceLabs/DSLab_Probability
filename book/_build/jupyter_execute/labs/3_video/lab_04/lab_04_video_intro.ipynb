{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Acquiring and Manipulating Videos\n",
    "\n",
    "<font size=\"6\"> Laboratory 4 </font> <br>\n",
    "<font size=\"3\"> Last updated July 25, 2023 </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#d97f00;\"> 00. Content </span>\n",
    "\n",
    "<font size=\"5\"> Mathematics </font>\n",
    "- N/A\n",
    "    \n",
    "<font size=\"5\"> Programming Skills </font>\n",
    "- Using Software Documentation\n",
    "- OpenCV (cv2)\n",
    "    \n",
    "<font size=\"5\"> Embedded Systems </font>\n",
    "- Thonny and MicroPython\n",
    "\n",
    "## <span style=\"color:#d97f00;\"> 0. Required Hardware </span>\n",
    "- Raspberry Pi Pico\n",
    "- Breadboard\n",
    "- USB connector\n",
    "- Camera (Arducam HM01B0)\n",
    "- 8 Wires"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:#6994a2\"> Write your name and email below: </h3>\n",
    "\n",
    "**Name:** \n",
    "\n",
    "**Email:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#d97f00;\"> 1. Reading Videos with OpenCV </span>\n",
    "\n",
    "In this lab, we will be using a Python library called OpenCV (cv2). According to the [official documentation](https://docs.opencv.org/4.x/d1/dfb/intro.html), \"OpenCV is an open-source library that includes several hundreds of computer vision algorithms.\" Today, we will primarily utilize it to read and display modified video frames, and we will manually handle the \"vision\" aspect of computer vision with our own functions.\n",
    "\n",
    "Run the following code cell to read the video file. The `vid.read()` function returns two values: a Boolean variable `success`, which is `True` if the frame was read without any errors, and `frame`, which represents the captured image from the video. Since the camera hardware connected to your Pico can only provide grayscale images, we will convert each frame to grayscale using the `cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)` function. To improve computation speed, we have scaled down each frame by a factor of 4.\n",
    "\n",
    "Once you run the cell, a separate window will pop up (potentially appearing behind other windows on your screen), displaying the smaller, grayscale video. The separate window will automatically close after reading the entire video. However, you can override this behavior by pressing the `Q` key on your keyboard.\n",
    "\n",
    "To begin, download the video file we'll be using for this lab: [test_vid.mov](https://github.com/TheDataScienceLabs/DSLab_Probability/blob/main/book/labs/3_video/lab_04/additional_files/test_vid.mov). This video is sourced from YouTube and depicts a bouncing ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('test_vid.mov')                  \n",
    "height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width  = vid.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "scale = 0.25\n",
    "new_size = (int(width*scale),int(height*scale))         # new frame dimensions, 4 times smaller than the original\n",
    "\n",
    "while vid.isOpened():                                    \n",
    "    success, frame = vid.read()                         # get the current frame (if there is one)\n",
    "    if not success:\n",
    "        print(\"Unable to read frame. Exiting ...\")\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)     # change the video from color to grayscale\n",
    "    frame = cv2.resize(frame,dsize=new_size)            # resize the frame to the new dimensions\n",
    "    cv2.imshow('frame', frame)                          # display 'frame' in the popup window\n",
    "    if cv2.waitKey(25) == ord('q'):                     # press Q on keyboard to stop\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()                                 # closes the popup when the video is over"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 1 </span>\n",
    "\n",
    "What type of variable is `frame`? What kind of datatype is stored in `frame`?\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 1 Below </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#d97f00;\"> 2. Modifying Videos </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 2 </span>\n",
    "\n",
    "Read the [documentation](https://docs.opencv.org/2.4/modules/highgui/doc/user_interface.html?highlight=waitkey) for the `waitKey` function.\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Play the video at a slower speed than its original playback speed.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 2 Part 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2** \n",
    "\n",
    "Play the video at a faster speed than its original playback speed.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 2 Part 2 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 3 </span>\n",
    "\n",
    "Play the video in reverse (backward). You don't need to refer to any additional documentation for this exercise.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 3 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 4 </span>\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Flip the visuals of the video over the y-axis.\n",
    "\n",
    "*Hint: There are multiple ways to accomplish this, but you can explore the flip functions in NumPy or OpenCV.*\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 4 Part 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "\n",
    "Flip the visuals of the video over the x-axis.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 4 Part 2 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to extract specific frames from a video is a useful skill. It can be used, for example, to trim the ends of the video or to remove a section in the middle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 5 </span>\n",
    "\n",
    "Play only the first 200 frames of the video. \n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 5 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:#d97f00;\"> 3. Connecting the Camera </span>\n",
    "\n",
    "This time, we will record our own videos using the Arducam HM01B0, which is a small camera that can be connected to the Pico. \n",
    "\n",
    "### Wiring Instructions\n",
    "\n",
    "Please ensure that your microcontroller is not connected to the computer while you are wiring components together. If you are unsure about your wiring, please consult the instructor. Use your jumper wires to establish the following connections:\n",
    "\n",
    "| HM01B0 | Pico |\n",
    "|--------|------|\n",
    "| VCC    | 3V3  |\n",
    "| SCL    | GP5  |\n",
    "| SDA    | GP4  |\n",
    "| VSYNC  | GP16 |\n",
    "| HREF   | GP15 |\n",
    "| PCLK   | GP14 |\n",
    "| DO     | GP6  |\n",
    "| GND    | GND  |\n",
    "\n",
    "Here is an image of the completed breadboard:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/TheDataScienceLabs/DSLab_Probability/main/book/labs/shared_files/connecting_the_camera/HM01B0_and_pico.png)\n",
    "\n",
    "<!-- ![img](camera.jpg)\n",
    "\n",
    "*Wiring the Arducam HM01B0 camera* \n",
    "\n",
    "![img](camerawiring.jpg)\n",
    "\n",
    "*Connections to the PICO on breadboard* -->\n",
    "\n",
    "To find the names of the pins on the Raspberry Pi Pico, you can refer to its pinout diagram located [here](https://datasheets.raspberrypi.com/pico/Pico-R3-A4-Pinout.pdf) or in the Extra Materials section. The HM01B0, on the other hand, should have its pins labeled.\n",
    "\n",
    "After confirming that the wiring is correct, press and hold the BOOTSEL button on the Pico while plugging it in. Download the [arducam.uf2](https://github.com/TheDataScienceLabs/DSLab_Probability/blob/main/book/labs/shared_files/connecting_the_camera/arducam.uf2) file and copy it onto the Pico's drive using your computer's file manager (it should be listed as an external drive: \"RPI-RP2\") and not with Thonny. Once the file transfer is complete, the Pico will automatically disconnect, and its LED will start blinking rapidly. \n",
    "\n",
    "Once the Pico has been successfully connected, please execute the following cell to ensure that we have successfully detected the Pico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import serial\n",
    "from serial.tools import list_ports\n",
    "\n",
    "PICO_HWID = \"2E8A\"\n",
    "\n",
    "\n",
    "def get_pico_port():\n",
    "    pico_ports = list(list_ports.grep(PICO_HWID))\n",
    "    if len(pico_ports) == 0:\n",
    "        raise Exception(\n",
    "            \"No Raspberry Pi Pico was detected. Check to make sure it is plugged in, and that no other programs are accessing it\"\n",
    "        )\n",
    "    return pico_ports[0].device\n",
    "\n",
    "\n",
    "print(\"Here are all the serial devices detected:\")\n",
    "for port in list_ports.comports():\n",
    "    print(port.device, port.hwid)\n",
    "\n",
    "port = get_pico_port()\n",
    "print(f\"\\nselected port {port} as most likely to have a raspberry pi pico\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing a still image\n",
    "\n",
    "Now that the Pico and camera have been connected, execute the following cell to capture a still image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = bytearray(96 * 96)\n",
    "img = np.zeros(shape=(96, 96), dtype=\"uint8\")\n",
    "\n",
    "with serial.Serial(port, timeout=1) as s:\n",
    "    s.read_until(b\"\\x55\\xAA\")\n",
    "    s.readinto(buffer)\n",
    "    img.flat[::-1] = buffer\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 6 </span>\n",
    "\n",
    "Use the camera to capture an image of yourself (or a neighbor) with your hand up and another image of yourself (or your neighbor) with your hands down. You are welcome to use more than two frames if desired. Use these frames to create a video where you move your hands up and down, lasting a few seconds.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 6 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming video\n",
    "\n",
    "Now that we can capture a still image, the next goal is to stream a video. Both cells need to be executed before the video is streamed to your screen. After running the first cell, a still image should pop up. Once you run the second cell, it will start streaming real-time video from your camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "render = ax.imshow(img, cmap='gray')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with serial.Serial(port, timeout=1) as s:\n",
    "        while True:\n",
    "            s.read_until(b\"\\x55\\xAA\")\n",
    "            s.readinto(buffer)\n",
    "            img.flat[::-1] = buffer\n",
    "            render.set_data(img)\n",
    "            fig.canvas.draw()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished, you will need to click the *\"Interrupt Kernel\"* button in Jupyter, which can be found at the top of the screen (the stop symbol) or under the Kernel menu."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#d97f00;\"> 4. Modifying Your Own Video </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 7 </span>\n",
    "\n",
    "Capture and save a list of frames using the camera.\n",
    "\n",
    "**Part 1:** Repeat Exercise 3 and Exercise 4 with your own video. \n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 7 Part 1 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2:** Create an Instagram boomerang effect using a small portion or the entire video. Here's an example of what a [boomerang effect](https://raw.githubusercontent.com/TheDataScienceLabs/DSLab_Probability/main/book/labs/3_video/lab_04/additional_files/jump-over-puddle-boomerang.gif) looks like:\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 7 Part 2 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3:** Choose an editing function we haven't mentioned yet (e.g., adding text, video filters, etc.) and give it a try on either the pre-recorded video or the ones you recorded using the camera.\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for Exercise 7 Part 3 Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Reflection </span>\n",
    "\n",
    "1. What was your favorite exercise in this lab?\n",
    "2. Which part of the lab did you find the most challenging?\n",
    "3. Which part of the lab was the easiest?\n",
    "\n",
    "<h3 style=\"background-color:#6994a2\"> Write Answers for the Reflection Below </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5733b5ebf5ecec2b002a59c36710d44decb4334b28aff8074b4cca610e6649ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}