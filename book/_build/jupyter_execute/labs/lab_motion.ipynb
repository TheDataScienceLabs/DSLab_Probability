{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a86c853b-b82f-4883-bf03-15a2c05b87db",
   "metadata": {},
   "source": [
    "# Week 8: Motion Detection\n",
    "\n",
    "<font size=\"6\"> Laboratory 5 </font> <br>\n",
    "<font size=\"3\"> Last updated April 24, 2023 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90879f5-f730-44da-ad7a-be77ee8b2eaa",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 00. Content </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba827722-0c2f-493b-a2d2-d7f0bda08882",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Mathematics </font>\n",
    "- probability mass functions\n",
    "     \n",
    "<font size=\"5\"> Programming Skills </font>\n",
    "- functions and modules\n",
    "    \n",
    "<font size=\"5\"> Embedded Systems </font>\n",
    "- Thonny and Micropython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef17dd-1c68-43ed-9406-c2b55840c4b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 0. Required Hardware </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec4e4a28-936f-4676-8286-c69f06d2ac08",
   "metadata": {},
   "source": [
    "- Microcontroller: Raspberry Pi Pico\n",
    "- Breadboard\n",
    "- USB connector\n",
    "- Camera"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60f85e09-35cc-47d9-b1d8-6e88b0fb6416",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write your name and email below: </h3>\n",
    "\n",
    "**Name:** me \n",
    "\n",
    "**Email:** me @purdue.edu\n",
    "\n",
    "*You may work in groups of 2-3 for this lab.*\n",
    "\n",
    "**Groupmate(s):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61de84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9b4a375-00e6-40d3-bea2-dcc8a1492083",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 1. Background Subtraction </span>\n",
    "\n",
    "There is a popular image processing technique called backgroud subtraction. The most effective way to use backgroud subtraction to detect motion is when\n",
    "1. the camera is stationary,\n",
    "2. the background is static,\n",
    "3. the lighting conditions do not change,\n",
    "4. minimal noise in the image.\n",
    "\n",
    "One scenario where all of these conditions are met is in production/manufacturing lines. For a more controlled indoor environment, there are rarely long-term changes.\n",
    "\n",
    "Essentially, background subtraction separates the background from the foregroud of an image. For example, if you set up a camera to monitor a doorway, then most of the time nothing is moving in the frame. So if we pick an initial reference frame, we can compare all of the frames after that point to the reference frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45b9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('test_vid.mov') \n",
    "height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width  = vid.get(cv2.CAP_PROP_FRAME_WIDTH) \n",
    "scale = 0.125                                           # smaller scale for faster computations\n",
    "new_size = (int(width*scale),int(height*scale))\n",
    "frames = []                                             # saving frames to a list so that you can try\n",
    "                                                        # methods quickly without reloading the video\n",
    "while vid.isOpened():   \n",
    "    success, frame = vid.read()\n",
    "    if not success:\n",
    "        print(\"Unable to read frame. Exiting ...\")\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame,dsize=new_size)\n",
    "    frames.append(frame)\n",
    "    cv2.imshow('frame', frame)                          # display grayscaled video resized, no other alterations\n",
    "    if cv2.waitKey(25) == ord('q'):                     # press Q on keyboard to stop\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5259bfd5",
   "metadata": {},
   "source": [
    "Background subtraction refers to a whole class of methods. We will only use one method for the scope of this lab. To see an example, we will use the same test video from the last lab. To keep things short, we won't go into detail on how `cv2.createBackgroundSubtractorMOG2()` works, but in general, this method is a little more resistant to illumination changes. The output of the background subtraction function is what is called a *mask*, which means **the output is a binary image**. Pixel values are either 0 (for the background) or 255 (for the foreground).\n",
    "Run the cell to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097e595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)      # define this before looping through the frames\n",
    "\n",
    "for f in frames:\n",
    "    img = fgbg.apply(f)\n",
    "    cv2.imshow('background subtracted frame',img)\n",
    "    if cv2.waitKey(25) == ord('q'):                                 # press Q on keyboard to stop\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "279f9240",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 2. Motion Detection and Localization </span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7636de42-f083-40b1-8510-b5a0e6a57eeb",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise </span>\n",
    "\n",
    "Suppose we apply background subtraction to each vidoe frame and we split up the video frame into a $M\\times N$ grid of $MN$ total blocks. Can you think of a (mathematical) rule to tell whether or not there is movement in a specific block?\n",
    "\n",
    "*Hint: Would the proportion of certain grayscale values be high/low when there is motion?*\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answer for Exercise Below </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f00a49",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c0d30f",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise </span>\n",
    "\n",
    "Using your camera, locate the area of motion in the video frame in real time (or near real time). You can use any method to do this, whether it be background subtraction, your answer to the previous exercise, some combination of the two, or anything else you can think of. Decide how to display where movement has been detected on the camera, such as having Python print a statement or drawing a rectangle on the frame.\n",
    "\n",
    "Display all code you used in a cell below.\n",
    "\n",
    "*Note: If you run into significant trouble with the hardware, try your method on the test video.*\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answer for Exercise Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e10cca26",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise </span>\n",
    "\n",
    "Describe in a paragraph or two how well the motion detector/locator works. What methods did your group try? What problems arose and were you able to resolve any of them?\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answer for Exercise Below </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58811bb8",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e907e1a3",
   "metadata": {},
   "source": [
    "## <span style=\"color:green;\"> Reflection </span>\n",
    "\n",
    "__1. What parts of the lab, if any, do you feel you did well? <br>\n",
    "2. What are some things you learned today? <br>\n",
    "3. Are there any topics that could use more clarification? <br>\n",
    "4. Do you have any suggestions on parts of the lab to improve?__\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for the Reflection Below </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58523e79",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5733b5ebf5ecec2b002a59c36710d44decb4334b28aff8074b4cca610e6649ad"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}